{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Breast Cancer Classification using Resnet Architecture and Pretrained Inception Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "dgFVvUTdgbDH",
        "colab_type": "code",
        "outputId": "5109fb10-c5fe-46ef-9133-a6c1f7637a7b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "# Colab library to upload files to notebook\n",
        "from google.colab import files\n",
        "\n",
        "# Install Kaggle library\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Upload kaggle API key file\n",
        "uploaded = files.upload()\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "!kaggle -v\n",
        "!kaggle datasets download -d paultimothymooney/breast-histopathology-images\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6e79de6f-bcf8-4e37-bca8-3ee6b9000d70\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-6e79de6f-bcf8-4e37-bca8-3ee6b9000d70\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "kaggle.json\n",
            "Uninstalling kaggle-1.5.6:\n",
            "  Successfully uninstalled kaggle-1.5.6\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.1.1\n",
            "Collecting kaggle==1.5.6\n",
            "  Downloading kaggle-1.5.6.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2020.4.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-py3-none-any.whl size=72859 sha256=9418545062341740e9e41d2242dfd064f89827075c50ab0fdea1c0316b3c7c43\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/3e/ff/77407ebac3ef71a79b9166a8382aecf88415a0bcbe3c095a01\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n",
            "Kaggle API 1.5.6\n",
            "Downloading breast-histopathology-images.zip to /content\n",
            " 99% 3.08G/3.10G [00:59<00:00, 48.5MB/s]\n",
            "100% 3.10G/3.10G [00:59<00:00, 56.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tWslWXlkchC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \\*.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjiArB8rf-Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "import os\n",
        "\n",
        "# initialize the path to the *original* input directory of images\n",
        "ORIG_INPUT_DATASET = \"/content/IDC_regular_ps50_idx5/\"\n",
        "\n",
        "# initialize the base path to the *new* directory that will contain\n",
        "# our images after computing the training and testing split\n",
        "BASE_PATH = \"/content\"\n",
        "\n",
        "# derive the training, validation, and testing directories\n",
        "TRAIN_PATH = os.path.sep.join([BASE_PATH, \"training\"])\n",
        "VAL_PATH = os.path.sep.join([BASE_PATH, \"validation\"])\n",
        "TEST_PATH = os.path.sep.join([BASE_PATH, \"testing\"])\n",
        "\n",
        "# define the amount of data that will be used training\n",
        "TRAIN_SPLIT = 0.8\n",
        "\n",
        "# the amount of validation data will be a percentage of the\n",
        "# *training* data\n",
        "VAL_SPLIT = 0.1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulvgki3NglUe",
        "colab_type": "code",
        "outputId": "e4a3966b-fa49-4882-8eeb-acf1ba631dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import AveragePooling2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import ZeroPadding2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import add\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "class ResNet:\n",
        "\t@staticmethod\n",
        "\tdef residual_module(data, K, stride, chanDim, red=False,\n",
        "\t\treg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "\t\t# the shortcut branch of the ResNet module should be\n",
        "\t\t# initialize as the input (identity) data\n",
        "\t\tshortcut = data\n",
        "\n",
        "\t\t# the first block of the ResNet module are the 1x1 CONVs\n",
        "\t\tbn1 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\tmomentum=bnMom)(data)\n",
        "\t\tact1 = Activation(\"relu\")(bn1)\n",
        "\t\tconv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False,\n",
        "\t\t\tkernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "\t\t# the second block of the ResNet module are the 3x3 CONVs\n",
        "\t\tbn2 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\tmomentum=bnMom)(conv1)\n",
        "\t\tact2 = Activation(\"relu\")(bn2)\n",
        "\t\tconv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride,\n",
        "\t\t\tpadding=\"same\", use_bias=False,\n",
        "\t\t\tkernel_regularizer=l2(reg))(act2)\n",
        "\n",
        "\t\t# the third block of the ResNet module is another set of 1x1\n",
        "\t\t# CONVs\n",
        "\t\tbn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\tmomentum=bnMom)(conv2)\n",
        "\t\tact3 = Activation(\"relu\")(bn3)\n",
        "\t\tconv3 = Conv2D(K, (1, 1), use_bias=False,\n",
        "\t\t\tkernel_regularizer=l2(reg))(act3)\n",
        "\n",
        "\t\t# if we are to reduce the spatial size, apply a CONV layer to\n",
        "\t\t# the shortcut\n",
        "\t\tif red:\n",
        "\t\t\tshortcut = Conv2D(K, (1, 1), strides=stride,\n",
        "\t\t\t\tuse_bias=False, kernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "\t\t# add together the shortcut and the final CONV\n",
        "\t\tx = add([conv3, shortcut])\n",
        "\n",
        "\t\t# return the addition as the output of the ResNet module\n",
        "\t\treturn x\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes, stages, filters,\n",
        "\t\treg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "\t\t# initialize the input shape to be \"channels last\" and the\n",
        "\t\t# channels dimension itself\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "\n",
        "\t\t# if we are using \"channels first\", update the input shape\n",
        "\t\t# and channels dimension\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "\t\t\tchanDim = 1\n",
        "\n",
        "\t\t# set the input and apply BN\n",
        "\t\tinputs = Input(shape=inputShape)\n",
        "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\tmomentum=bnMom)(inputs)\n",
        "\n",
        "\t\t# apply CONV => BN => ACT => POOL to reduce spatial size\n",
        "\t\tx = Conv2D(filters[0], (5, 5), use_bias=False,\n",
        "\t\t\tpadding=\"same\", kernel_regularizer=l2(reg))(x)\n",
        "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\tmomentum=bnMom)(x)\n",
        "\t\tx = Activation(\"relu\")(x)\n",
        "\t\tx = ZeroPadding2D((1, 1))(x)\n",
        "\t\tx = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "\t\t# loop over the number of stages\n",
        "\t\tfor i in range(0, len(stages)):\n",
        "\t\t\t# initialize the stride, then apply a residual module\n",
        "\t\t\t# used to reduce the spatial size of the input volume\n",
        "\t\t\tstride = (1, 1) if i == 0 else (2, 2)\n",
        "\t\t\tx = ResNet.residual_module(x, filters[i + 1], stride,\n",
        "\t\t\t\tchanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "\t\t\t# loop over the number of layers in the stage\n",
        "\t\t\tfor j in range(0, stages[i] - 1):\n",
        "\t\t\t\t# apply a ResNet module\n",
        "\t\t\t\tx = ResNet.residual_module(x, filters[i + 1],\n",
        "\t\t\t\t\t(1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "\t\t# apply BN => ACT => POOL\n",
        "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\tmomentum=bnMom)(x)\n",
        "\t\tx = Activation(\"relu\")(x)\n",
        "\t\tx = AveragePooling2D((8, 8))(x)\n",
        "\n",
        "\t\t# softmax classifier\n",
        "\t\tx = Flatten()(x)\n",
        "\t\tx = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
        "\t\tx = Activation(\"softmax\")(x)\n",
        "\n",
        "\t\t# create the model\n",
        "\t\tmodel = Model(inputs, x, name=\"resnet\")\n",
        "\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32d6SU5Dgpwb",
        "colab_type": "code",
        "outputId": "95dcf5d6-890b-4f74-ec89-14515c04a965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# USAGE\n",
        "# python build_dataset.py\n",
        "\n",
        "# import the necessary packages\n",
        "from imutils import paths\n",
        "import random\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# grab the paths to all input images in the original input directory\n",
        "# and shuffle them\n",
        "imagePaths = list(paths.list_images(ORIG_INPUT_DATASET))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)\n",
        "\n",
        "# compute the training and testing split\n",
        "i = int(len(imagePaths) *TRAIN_SPLIT)\n",
        "trainPaths = imagePaths[:i]\n",
        "testPaths = imagePaths[i:]\n",
        "\n",
        "# we'll be using part of the training data for validation\n",
        "i = int(len(trainPaths) *VAL_SPLIT)\n",
        "valPaths = trainPaths[:i]\n",
        "trainPaths = trainPaths[i:]\n",
        "\n",
        "# define the datasets that we'll be building\n",
        "datasets = [\n",
        "\t(\"training\", trainPaths,TRAIN_PATH),\n",
        "\t(\"validation\", valPaths,VAL_PATH),\n",
        "\t(\"testing\", testPaths,TEST_PATH)\n",
        "]\n",
        "\n",
        "# loop over the datasets\n",
        "for (dType, imagePaths, baseOutput) in datasets:\n",
        "\t# show which data split we are creating\n",
        "\tprint(\"[INFO] building '{}' split\".format(dType))\n",
        "\n",
        "\t# if the output base output directory does not exist, create it\n",
        "\tif not os.path.exists(baseOutput):\n",
        "\t\tprint(\"[INFO] 'creating {}' directory\".format(baseOutput))\n",
        "\t\tos.makedirs(baseOutput)\n",
        "\n",
        "\t# loop over the input image paths\n",
        "\tfor inputPath in imagePaths:\n",
        "\t\t# extract the filename of the input image along with its\n",
        "\t\t# corresponding class label\n",
        "\t\tfilename = inputPath.split(os.path.sep)[-1]\n",
        "\t\tlabel = inputPath.split(os.path.sep)[-2]\n",
        "\n",
        "\t\t# build the path to the label directory\n",
        "\t\tlabelPath = os.path.sep.join([baseOutput, label])\n",
        "\n",
        "\t\t# if the label output directory does not exist, create it\n",
        "\t\tif not os.path.exists(labelPath):\n",
        "\t\t\tprint(\"[INFO] 'creating {}' directory\".format(labelPath))\n",
        "\t\t\tos.makedirs(labelPath)\n",
        "\n",
        "\t\t# construct the path to the destination image and then copy\n",
        "\t\t# the image itself\n",
        "\t\tp = os.path.sep.join([labelPath, filename])\n",
        "\t\tshutil.copy2(inputPath, p)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] building 'training' split\n",
            "[INFO] 'creating /content/training' directory\n",
            "[INFO] 'creating /content/training/0' directory\n",
            "[INFO] 'creating /content/training/1' directory\n",
            "[INFO] building 'validation' split\n",
            "[INFO] 'creating /content/validation' directory\n",
            "[INFO] 'creating /content/validation/0' directory\n",
            "[INFO] 'creating /content/validation/1' directory\n",
            "[INFO] building 'testing' split\n",
            "[INFO] 'creating /content/testing' directory\n",
            "[INFO] 'creating /content/testing/0' directory\n",
            "[INFO] 'creating /content/testing/1' directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ0FccG6j57c",
        "colab_type": "code",
        "outputId": "cce92806-efbd-433e-9929-8752ab97c261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "%matplotlib inline\n",
        "# import the necessary packages\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# define the total number of epochs to train for along with the\n",
        "# initial learning rate and batch size\n",
        "NUM_EPOCHS = 3\n",
        "INIT_LR = 1e-1\n",
        "BS = 32\n",
        "\n",
        "# determine the total number of image paths in training, validation,\n",
        "# and testing directories\n",
        "totalTrain = len(list(paths.list_images(TRAIN_PATH)))\n",
        "totalVal = len(list(paths.list_images(VAL_PATH)))\n",
        "totalTest = len(list(paths.list_images(TEST_PATH)))\n",
        "\n",
        "# initialize the training training data augmentation object\n",
        "trainAug = ImageDataGenerator(\n",
        "\trescale=1 / 255.0,\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.05,\n",
        "\twidth_shift_range=0.05,\n",
        "\theight_shift_range=0.05,\n",
        "\tshear_range=0.05,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "\n",
        "# initialize the validation (and testing) data augmentation object\n",
        "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
        "\n",
        "# initialize the training generator\n",
        "trainGen = trainAug.flow_from_directory(\n",
        "\tTRAIN_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(64, 64),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=True,\n",
        "\tbatch_size=BS)\n",
        "\n",
        "# initialize the validation generator\n",
        "valGen = valAug.flow_from_directory(\n",
        "\tVAL_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(64, 64),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BS)\n",
        "\n",
        "# initialize the testing generator\n",
        "testGen = valAug.flow_from_directory(\n",
        "\tTEST_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(64, 64),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BS)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 199818 images belonging to 2 classes.\n",
            "Found 22201 images belonging to 2 classes.\n",
            "Found 55505 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMi0SLEfWj1U",
        "colab_type": "code",
        "outputId": "3ccf688e-729c-4530-8d65-dd51fc8630b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initialize our ResNet model and compile it\n",
        "model = ResNet.build(64, 64, 3, 2, (3, 4, 6),\n",
        "\t(64, 128, 256, 512), reg=0.0005)\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64, 64, 3)    12          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 64, 64, 64)   4800        batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 66, 66, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 32)   2048        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 32)   9216        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 128)  4096        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 128)  8192        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 128)  0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 32)   4096        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 32)   128         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 32)   9216        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 128)  4096        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 128)  0           conv2d_8[0][0]                   \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 32)   4096        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 32)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 32)   9216        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 128)  4096        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 128)  0           conv2d_11[0][0]                  \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 64)   8192        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 64)   36864       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 256)  16384       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 256)  32768       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 256)  0           conv2d_14[0][0]                  \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 64)   16384       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 64)   256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 64)   36864       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 64)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 256)  16384       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   16384       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 64)   36864       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 256)  16384       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 256)  0           conv2d_21[0][0]                  \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 256)  1024        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 256)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   16384       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 64)   36864       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 256)  16384       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 256)  0           conv2d_24[0][0]                  \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 256)  1024        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 256)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 128)  32768       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 128)  512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 128)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 128)    147456      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 128)    512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 128)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 512)    65536       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 512)    131072      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 512)    0           conv2d_27[0][0]                  \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 512)    2048        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 512)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 128)    65536       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 128)    512         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 128)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 128)    147456      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 128)    512         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 128)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 512)    65536       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 512)    0           conv2d_31[0][0]                  \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 512)    2048        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 512)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 128)    65536       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 128)    512         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 128)    147456      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 128)    512         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 512)    65536       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 512)    0           conv2d_34[0][0]                  \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 512)    2048        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 512)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 128)    65536       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 128)    512         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 128)    147456      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 128)    512         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 512)    65536       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 512)    0           conv2d_37[0][0]                  \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 512)    2048        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 512)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 128)    65536       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 128)    512         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 128)    147456      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 128)    512         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 128)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 512)    65536       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 512)    0           conv2d_40[0][0]                  \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 8, 8, 512)    2048        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 512)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 128)    65536       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 8, 8, 128)    512         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 8, 8, 128)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 8, 8, 128)    147456      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 8, 8, 128)    512         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 8, 8, 128)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 8, 8, 512)    65536       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 512)    0           conv2d_43[0][0]                  \n",
            "                                                                 add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 8, 8, 512)    2048        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 8, 8, 512)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            1026        flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 2)            0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 2,164,174\n",
            "Trainable params: 2,150,472\n",
            "Non-trainable params: 13,702\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu-KdT95lvnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "H = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=totalTrain // BS,\n",
        "\tvalidation_data=valGen,\n",
        "\tvalidation_steps=totalVal // BS,\n",
        "\tepochs=NUM_EPOCHS)\n",
        "\n",
        "# reset the testing generator and then use our trained model to\n",
        "# make predictions on the data\n",
        "print(\"[INFO] evaluating network...\")\n",
        "testGen.reset()\n",
        "predIdxs = model.predict_generator(testGen,\n",
        "\tsteps=(totalTest // BS) + 1)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testGen.classes, predIdxs,\n",
        "\ttarget_names=testGen.class_indices.keys()))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = NUM_EPOCHS\n",
        "%matplotlib inline\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK1iowkn8UD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/testing'\n",
        "testGen.reset()\n",
        "testGen = valAug.flow_from_directory(\n",
        "\tPATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(64, 64),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BS)\n",
        "\n",
        "predIdxs = model.predict_generator(testGen,\n",
        "\tsteps=(totalTest // BS) + 1)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "test_df = pd.DataFrame()\n",
        "id = []\n",
        "for x in glob('/content/testing/0/*'):\n",
        "    id.append(x)\n",
        "for x in glob('/content/testing/1/*'):\n",
        "    id.append(x)\n",
        "test_df['id'] = id\n",
        "test_df['category'] = predIdxs\n",
        "print(test_df)\n",
        "test_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW02nWjO-7xI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = test_df['id'].tolist()\n",
        "y_true = []\n",
        "for x in a:\n",
        "    y_true.append(int(x[-5]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB4JpJul-bO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "dict_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n",
        "confusion_mtx = confusion_matrix(y_true, predIdxs) \n",
        "plot_confusion_matrix(confusion_mtx, classes = list(dict_characters.values())) \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zmEbIbFRgbHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper Functions  Learning Curves and Confusion Matrix\n",
        "\n",
        "def plotKerasLearningCurve():\n",
        "    plt.figure(figsize=(10,5))\n",
        "    metrics = np.load('logs.npy')[()]\n",
        "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
        "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
        "        l = np.array(metrics[k])\n",
        "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
        "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
        "        y = l[x]\n",
        "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
        "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
        "    plt.legend(loc=4)\n",
        "    plt.axis([0, None, None, None]);\n",
        "    plt.grid()\n",
        "    plt.xlabel('Number of epochs')\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize = (5,5))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "def plot_learning_curve(history):\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig('./accuracy_curve.png')\n",
        "    #plt.clf()\n",
        "    # summarize history for loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig('./loss_curve.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq91d28E7D2-",
        "colab_type": "code",
        "outputId": "ae604136-0708-4ad1-8875-a3f427fe0747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DlA2LMmeGR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images = glob('/content/testing/*/*')\n",
        "from google.colab.patches import cv2\n",
        "from keras.preprocessing.image import img_to_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avh6St80aceF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f2fbf423-1a62-4a6f-d0f1-ae2401f53fc3"
      },
      "source": [
        "print(test_images[30000])\n",
        "a = test_images[30000]\n",
        "a = cv2.imread(a)\n",
        "a = cv2.resize(a,(64,64))\n",
        "a = img_to_array(a)\n",
        "a = a/255.0\n",
        "x = np.expand_dims(a, axis=0)\n",
        "print(x.shape)\n",
        "model.predict(x, verbose=1)[0].argmax(axis=0)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/testing/0/10290_idx5_x2501_y1251_class0.png\n",
            "(1, 64, 64, 3)\n",
            "\r1/1 [==============================] - 0s 15ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q6fRJqL7Q0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list all data in history\n",
        "%matplotlib inline\n",
        "print(H.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(H.history['accuracy'])\n",
        "plt.plot(H.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(H.history['loss'])\n",
        "plt.plot(H.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVyQgdOQfybW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (75, 75, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "last_output = last_layer.output\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "x = layers.Dense  (2, activation='softmax')(x)           \n",
        "\n",
        "model1 = Model( pre_trained_model.input, x) \n",
        "\n",
        "model1.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMwNF28cggTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2efa9c7d-0162-4296-fd9b-610cccc628cf"
      },
      "source": [
        "trainAug = ImageDataGenerator(\n",
        "\trescale=1 / 255.0,\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.05,\n",
        "\twidth_shift_range=0.05,\n",
        "\theight_shift_range=0.05,\n",
        "\tshear_range=0.05,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "\n",
        "# initialize the validation (and testing) data augmentation object\n",
        "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
        "\n",
        "# initialize the training generator\n",
        "trainGen = trainAug.flow_from_directory(\n",
        "\tTRAIN_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(75, 75),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=True,\n",
        "\tbatch_size=BS)\n",
        "\n",
        "# initialize the validation generator\n",
        "valGen = valAug.flow_from_directory(\n",
        "\tVAL_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(75, 75),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BS)\n",
        "\n",
        "# initialize the testing generator\n",
        "testGen = valAug.flow_from_directory(\n",
        "\tTEST_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(75, 75),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BS)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 199818 images belonging to 2 classes.\n",
            "Found 22201 images belonging to 2 classes.\n",
            "Found 55505 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGkpCHK2gS-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=5\n",
        "history = model1.fit(trainGen,\n",
        "                              validation_data=valGen,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=epochs,\n",
        "                              validation_steps=50,\n",
        "                              verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05pkMMPuiVav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list all data in history\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEcQLH6hiu64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/testing'\n",
        "testGen.reset()\n",
        "testGen = valAug.flow_from_directory(\n",
        "\tPATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(75, 75),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BS)\n",
        "\n",
        "predIdxs = model1.predict_generator(testGen,\n",
        "\tsteps=(totalTest / BS))\n",
        "print(len(predIdxs))\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "print(len(predIdxs))\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "test_df = pd.DataFrame()\n",
        "id = []\n",
        "for x in glob('/content/testing/0/*'):\n",
        "    id.append(x)\n",
        "for x in glob('/content/testing/1/*'):\n",
        "    id.append(x)\n",
        "test_df['id'] = id\n",
        "test_df['category'] = predIdxs\n",
        "print(test_df)\n",
        "test_df.to_csv('submissionInc.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuyvTLVqrJYl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "bc940a8e-704a-4410-b34a-833e61ca5031"
      },
      "source": [
        "a = test_df['id'].tolist()\n",
        "y_true = []\n",
        "for x in a:\n",
        "    y_true.append(int(x[-5]))\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "dict_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n",
        "confusion_mtx = confusion_matrix(y_true, predIdxs) \n",
        "plot_confusion_matrix(confusion_mtx, classes = list(dict_characters.values())) \n",
        "plt.show()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6U9fqvkqVWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_images[30000])\n",
        "a = test_images[30000]\n",
        "a = cv2.imread(a)\n",
        "a = cv2.resize(a,(75,75))\n",
        "a = img_to_array(a)\n",
        "a = a/255.0\n",
        "x = np.expand_dims(a, axis=0)\n",
        "print(x.shape)\n",
        "model1.predict(x, verbose=1)[0].argmax(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}